I"”<p>In this post, by â€œlearning theoryâ€ I really mean â€œstatistical learning theory,â€ rather than what social scientists mean by â€œsocial learningâ€. In machine learning and computer science, a large amount of research is going into creating models of how to â€œlearn from dataâ€. A key lesson from Boyd and Richerson is the interplay between â€œsocialâ€ learning (or â€œcultural transmissionâ€) from peers and conspecifics, and â€œguided variationâ€ or â€œindividual learningâ€. Across a variety of disciplines, and especially in evolutionary biology, social psychology, economics, and anthropology, there is a large literature on the circumstances that govern when it is advantageous to learn via trial and error in the environment versus imitate peers.</p>
<p>Leslie Valiant <span class="citation" data-cites="valiant1984theory">(Valiant 1984,<span class="citation" data-cites="valiant2013probably">@valiant2013probably</span>)</span> built the mathematical framework for understanding the conditions under which a model can â€œlearnâ€ a concept or target from data. That framework, â€œprobably approximately correctâ€ or â€œPACâ€ learning, is the foundation for statistical learning theory, which in turn underpins the â€œpredictiveâ€ branch of statistics and machine learning. In PAC learning, the learner/agent selects a hypothesis (algorithm/model) from among a permissible space of models that has low generalization error (the â€œapproximately correctâ€ part) with high probability (the â€œprobably correctâ€ part). Valiant (2013) then took a stab at connecting this with evolution in his popular exposition of PAC learning theory, with variable success.</p>
<p>How do we do this right? Some version of PAC learning is occurring at two scales in the case of cultural evolution:</p>
<ol type="1">
<li>Developmentally and ontogenetically: organisms learn from their environment, both in individual learning (which is really probably a combination of what machine learning researchers now call â€œreinforcement learningâ€ and forming â€œgenerative adversarial modelsâ€ depending upon the mechanism", and social learning, which boil down to mechanisms like imitating peers, teaching by parents, oblique peers (other adults), and age peers.<br />
</li>
<li>Evolutionarily: Some of the variation â€œlearnedâ€ developmentally is then transmitted through social learning to others and thus becomes a cultural lineage.</li>
</ol>
<p>The open questions and opportunities for detailed modeling and research abound for someone who knows both research areas. Open questions include:</p>
<ol type="1">
<li>Can we recast social learning through imitation and teaching as a â€œtransfer learningâ€ process or a modification of transfer learning?</li>
<li>Can we model an individual learner as having a set of tasks (targets) for learning, who then does a combination of reinforcement learning (guided variation), transfer learning (imitation or teaching), and adversarial learning (for game theoretic strategic targets)? We need a name for this kind of amalgamated model â€“ perhaps â€œfacultative learnersâ€?</li>
<li>Can we create a two-level model which incorporates developmental learning and evolutionary learning by having a population of â€œfacultativeâ€ learners all aimed at the same set of multiple targets, but then put a genetic algorithm on top to create a population level process which creates evolutionary change over generations?</li>
<li>In creating the population level process, we need a way to â€œscreen offâ€ the details of individual variation and success on individual tasks from â€œoverall fitnessâ€. Is it appropriate to use the framework of â€œstatistical query learningâ€ to model this selection and screening-off process at the population level? Or something simpler?<br />
</li>
<li>Perhaps SQL (statistical query learning) is how we represent direct bias or success-based learning in selecting the targets for transfer learning?</li>
</ol>
<p>Why do we go to all this trouble?</p>
<p>Fundamentally the issue is how we get â€œthickerâ€ models for social learning, but retain the ability to do statistical modeling with them. Population genetics models are sort of a dead end for this task. Statistical learning theory is probably the best way to model the â€œevo-devoâ€ of cultural transmission, in a stochastic context, with realistic â€œtargetsâ€ and variation. Then we just need to coarse-grain it to the evolutionary scale with a population-level process on top.</p>
<p>There is a massive amount of work here, but if this approach can be outlined with real exemplars in a couple of studies, there is a new paradigm here, and one supported by a vast amount of real work and available software to work with.</p>
<h3 id="previous-notes">Previous Notes</h3>
<ul>
<li>From 2016: <a href="/essays/2016/03/03/cultural-evolution-intentionality-pac-learning.html">Intentionality and Cultural Evolution - Towards a Generalized Learning Theory Account</a></li>
</ul>
<h3 id="references-cited" class="unnumbered">References Cited</h3>
<div id="refs" class="references" role="doc-bibliography">
<div id="ref-valiant2013probably">
<p>Valiant, Leslie. 2013. <em>Probably Approximately Correct: Natureâ€™s Algorithms for Learning and Prospering in a Complex World</em>. Basic Books.</p>
</div>
<div id="ref-valiant1984theory">
<p>Valiant, Leslie G. 1984. â€œA Theory of the Learnable.â€ <em>Communications of the ACM</em> 27 (11). ACM New York, NY, USA: 1134â€“42.</p>
</div>
</div>
:ET